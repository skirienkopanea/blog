---
layout: post
title:  "Computer Networks Summary"
date:   2021-04-11 00:51:00 +0200
categories: architecture
tags: CSE1405
---
{% include math.html %}
<!--more-->
  
# Table of Contents
- [Table of Contents](#table-of-contents)
  - [Network Performance Metrics](#network-performance-metrics)
    - [Byte conversion](#byte-conversion)
    - [Speed](#speed)
  - [Bitwise operations](#bitwise-operations)
    - [display the integers as a binary string](#display-the-integers-as-a-binary-string)
    - [Selecting](#selecting)
    - [Moving](#moving)
    - [Length](#length)
    - [Bitcount](#bitcount)
    - [Java operators](#java-operators)
    - [Java methods](#java-methods)
  - [Network Layers](#network-layers)
    - [Open Systems Interconnections (OSI) Model](#open-systems-interconnections-osi-model)
    - [TCP/IP model](#tcpip-model)
    - [Units of data](#units-of-data)
  - [Error Detection](#error-detection)
    - [Parity bits and checksums](#parity-bits-and-checksums)
    - [Error Detection](#error-detection-1)
    - [Error correction](#error-correction)
    - [Parity bits](#parity-bits)
    - [Checksum](#checksum)
    - [Checksum in 1s complement](#checksum-in-1s-complement)
    - [Hamming distance](#hamming-distance)
    - [Cyclic Redunancy Check (CRC)](#cyclic-redunancy-check-crc)
    - [Hamming code (n+k,n)](#hamming-code-nkn)
    - [Parity block](#parity-block)
      - [Sender](#sender)
      - [Receiver](#receiver)
    - [Overhead Analysis](#overhead-analysis)
    - [Burst Errors](#burst-errors)
  - [Services](#services)
    - [Connection-Oriented service](#connection-oriented-service)
    - [Connectionless service](#connectionless-service)
    - [Reliable service](#reliable-service)
    - [Connectionless application](#connectionless-application)
    - [Acknowledged datagram](#acknowledged-datagram)
    - [Request-reply service](#request-reply-service)
  - [Data link layer](#data-link-layer)
    - [Services Provided to the Network layer](#services-provided-to-the-network-layer)
      - [Unacknowledged connectionless service](#unacknowledged-connectionless-service)
      - [acknowledged connectionless service](#acknowledged-connectionless-service)
      - [connection-oriented service](#connection-oriented-service-1)
  - [Data link layer framing](#data-link-layer-framing)
    - [How to determine start of a frame](#how-to-determine-start-of-a-frame)
      - [Byte Stuffing: Flag determines beginning and end of the frame.](#byte-stuffing-flag-determines-beginning-and-end-of-the-frame)
      - [Dealing with lost frames: Automatic Repeat ReQuest (ARQ) for noisy channel uses acknowledgement](#dealing-with-lost-frames-automatic-repeat-request-arq-for-noisy-channel-uses-acknowledgement)
      - [Sliding windows](#sliding-windows)
      - [Example](#example)
  - [MAC Sublayer](#mac-sublayer)
    - [Channel allocation protocols](#channel-allocation-protocols)
    - [ALOHA](#aloha)
    - [Carrier-Sense Multiple Access (CSMA)](#carrier-sense-multiple-access-csma)
    - [1-persistent](#1-persistent)
    - [Nonpersistent CSMA](#nonpersistent-csma)
    - [p-persistent](#p-persistent)
    - [Channel utilization comparision](#channel-utilization-comparision)
    - [CSMA with Collision Detection (cable)](#csma-with-collision-detection-cable)
    - [Collision-free protocols](#collision-free-protocols)
      - [Token ring](#token-ring)
      - [Bit-map protocol](#bit-map-protocol)
      - [Binary countdown](#binary-countdown)
    - [Multiple access with collision avoidance (MACA) (wireless)](#multiple-access-with-collision-avoidance-maca-wireless)
  - [Ethernet](#ethernet)
  - [Wifi (802.11 standard)](#wifi-80211-standard)
  - [LAN](#lan)
    - [Hub](#hub)
    - [Switch](#switch)
  - [Network layer](#network-layer)
    - [The connection-less model](#the-connection-less-model)
    - [Connection-oriented service](#connection-oriented-service-2)
  - [Routing](#routing)
    - [Routing tables](#routing-tables)
    - [Distance vector routing](#distance-vector-routing)
    - [Link state routing](#link-state-routing)
    - [Hierarchical routing](#hierarchical-routing)
    - [Congestion control](#congestion-control)
      - [Prevent congestion by increasing available bandwidth](#prevent-congestion-by-increasing-available-bandwidth)
      - [Traffic aware routing](#traffic-aware-routing)
      - [Admission control](#admission-control)
      - [Traffic throttling](#traffic-throttling)
      - [Load shedding](#load-shedding)
  - [Internetworking](#internetworking)
    - [Tunneling](#tunneling)
    - [Packet fragmentation](#packet-fragmentation)
      - [Transparent fragmentation](#transparent-fragmentation)
      - [Nontransparent fragmentation](#nontransparent-fragmentation)
      - [MTU discovery](#mtu-discovery)
  - [Internet protocols](#internet-protocols)
    - [IPv4](#ipv4)
    - [Network Address Translation (NAT)](#network-address-translation-nat)
    - [IPv6](#ipv6)
    - [Internet control protocols](#internet-control-protocols)
      - [ICMP](#icmp)
      - [Address Resolution Protocol (ARP)](#address-resolution-protocol-arp)
      - [Dynamic Host Configuration Protocol (DHCP)](#dynamic-host-configuration-protocol-dhcp)
  - [Gateway protocols](#gateway-protocols)
    - [Routing in the internet](#routing-in-the-internet)
    - [Open ShortestPath First (OSPF)](#open-shortestpath-first-ospf)
    - [Border Gatweay Protocol (BGP)](#border-gatweay-protocol-bgp)
  - [Transport layer](#transport-layer)
    - [Addressing and Connections](#addressing-and-connections)
    - [Segment Headers](#segment-headers)
    - [User Datagram Protocl (UDP)](#user-datagram-protocl-udp)
    - [Transmission Control Protocol (TCP)](#transmission-control-protocol-tcp)
    - [TCP/UDP reliability measures](#tcpudp-reliability-measures)
      - [Checksum](#checksum-1)
      - [Sequence numbers (of the TCP, not Data Link layer)](#sequence-numbers-of-the-tcp-not-data-link-layer)
      - [Initial sequence number](#initial-sequence-number)
      - [Clock-based sequence numbers](#clock-based-sequence-numbers)
      - [Repeated squence numbers](#repeated-squence-numbers)
      - [Modern TCP sequence number](#modern-tcp-sequence-number)
    - [Establishing a TCP connection (Three-way handshake)](#establishing-a-tcp-connection-three-way-handshake)
    - [TCP acknolwedgements](#tcp-acknolwedgements)
    - [Duplicate ACK](#duplicate-ack)
    - [Crash recovery](#crash-recovery)
  - [Acknowledgements and error detection/correction differences between data link layer and transport layer](#acknowledgements-and-error-detectioncorrection-differences-between-data-link-layer-and-transport-layer)
    - [Multiplexing](#multiplexing)
  - [Difference between flow control and congestion control](#difference-between-flow-control-and-congestion-control)
  - [TCP Flow control](#tcp-flow-control)
  - [TCP congestion control](#tcp-congestion-control)
    - [Congestion signals](#congestion-signals)
    - [Sharing bandwidth](#sharing-bandwidth)
    - [TCP implmentation of congestion control](#tcp-implmentation-of-congestion-control)
  - [TCP connection release/termination](#tcp-connection-releasetermination)
    - [Asymmetric disconnect](#asymmetric-disconnect)
    - [Symmetric disconnect (used by TCP)](#symmetric-disconnect-used-by-tcp)
  - [Aplication Layer](#aplication-layer)
    - [DNS](#dns)
    - [Name servers](#name-servers)
  - [Email](#email)
    - [Instant messaging vs email](#instant-messaging-vs-email)
  - [World Wide Web](#world-wide-web)
    - [HTTP requests](#http-requests)
    - [HTTP response codes](#http-response-codes)
    - [MIME types in the Web](#mime-types-in-the-web)

## Network Performance Metrics
### Byte conversion
* bit = just one binary digit
* ASCII character = 7 bits, often stored in 8 bits
* \\(Byte=8\ bits\\)
* The size of a `word` depends on the architecture you're working in. In `x86 assembly language`, regardless of the machine word size:
  *  `WORD` = 2 bytes
  *  `long` (doubleworld: `DWORD`) = 4 bytes
  *  `QUADWORD` (`QWORD`) = 8 bytes  are used for 2, 4 and 8 byte sizes.
*  char = 1 byte
*  short = 2 bytes
*  int = 32 bytes
*  long = 64 bytes
*  float = 32 bytes
*  double = 64 bytes 
* \\(KB=2^{10}\ bytes\\)
* \\(MB=2^{20}\ bytes\\)
* \\(GB=2^{30}\ bytes\\)
* \\(TB=2^{40}\ bytes\\) 
* frame: m data bits + r redunancy check bits
  * codeword: n-bit unit containing 1 frame. where n = m + r
  * corate: fraction of the codeword that is not redundant: m/n

### Speed
* Bandwidth: **Amount of total data that can maximally be sent via a connection per time unit**. (Max throughput) i.e. 10MB/s
* Latency: **bit travel time** from A to B. i.e. 20ms
* file transmission time (i.e. ms): **Time it takes to send all** bits of the message: (buffer) + file size / transmission rate 
  * Transmission rate: **sent bits per unit of time** (usually the bandwidth or smaller)
* Packet Delivery Time (ms): file transmission time + latency
* Throughput (**data transmitted per unit** i.e. 5 MB/s): file size / packet delivery time
* Overhead percentage: supportive info/total data
  * Total data = goodput + supportive info
  * goodput: actual data
* Packet loss is associated with a probaiblity p
* Jitter: variance in transmission delay (in latency)
  * Data might have been lost and resent without it being apparent to the user in anything but jitter. 

## Bitwise operations

### display the integers as a binary string
* Java:
```java
Long.toBinaryString(6) => "110"
```

* Python:
```python
format(6, 'b') => '110'
```

### Selecting
* To select parts of a binary sequence you can make use of bit masks. A bit mask is a binary sequence with 1s in the positions that are to be selected. This bit mask is then bitwise-AND'ed with the binary sequence. For example:
```
10110110 (input) AND 11110000 (mask) => 10110000
```

### Moving
* To move the selected part left or right in the sequence, bitwise-shifts can be used. A shift moves the entire sequence left or right depending on the chosen operator. For example:
```
10110110 LEFT_SHIFT 1  => 101101100
10110110 LEFT_SHIFT 2  => 1011011000
10110110 RIGHT_SHIFT 1 => 01011011
10110110 RIGHT_SHIFT 4 => 00001011
```

* Be careful when shifting numbers by more than 32 steps. This will overflow if the number is not a 64-bit integer
Combining
To combine multiple bit sequences, a bitwise-OR can be used. For example:
```
10110000 OR 00000110 => 10110110
```

### Length
* To calculate the length of the binary sequence (measured from the highest 1 bit), you can make use of:
* Generic:
```
floor(log2(10110110)) + 1 => 8
```
* Java:
```java
long bitSequence = Long.parseLong("10110110", 2)
Math.floor(Math.log(bitSequence)/ Math.log(2)) + 1 => 8
```
* Python:
```python
bit_sequence = int('10110110', 2)
bit_sequence.bit_length() => 8
```

### Bitcount
* To calculate the amount of 1s in a binary sequence, you can make use of:
* Generic:
```
bit_count(integer)
count = 0
while int
  count += (int AND 1)
  int = int RIGHT_SHIFT 1
return count
```
* Java:
```java
long bit_sequence = Long.parseLong("110", 2)
Long.bitCount(bit_sequence) => 2
```
* Python:
```python
bit_sequence = int('110', 2)
bit_count(6) => 2
```

### Java operators
* bitwise and: &
* bitwise or: \|
* bitwise XOR*: ^ (it's a binary sum without carry over)
* bitwise compliment: ~
* left shift: <<
* right shift: >>

### Java methods
```java
private static void debugging() {
    // Showing binary representation of an integer value for debugging:
    long integerNotation = 6;
    String binaryStringNotation = Long.toBinaryString(integerNotation);
    System.out.println(integerNotation + " -> " + binaryStringNotation);
  }

  private static void binaryNotation() {
    // Creating integer from binary notation:
    long integer1 = Long.parseLong("110", 2);
    // Add L on the end for values larger than 32-bit
    long integer2 = 0b110;
    System.out.println(integer1);
    System.out.println(integer2);
  }

  private static void createBitSequence() {
    // Creating 010110001 (bit sequences) from scratch
    long res = 0;
    // or res = res | (1L << 7)
    res |= 1L << 7;
    res |= 1L << 5;
    res |= 1L << 4;
    res |= 1L;
    System.out.println(Long.toBinaryString(res));
  }

  private static void flippingBit() {
    // Flipping a bit in 10(1)1 to become 10(0)1
    long unflipped = 0b1011;
    // XOR original value with 10
    long flipped = unflipped ^ (1L << 1);
    System.out.println(Long.toBinaryString(unflipped) + " -> " + Long.toBinaryString(flipped));
  }

  private static void prepending() {
    // Prepending the bit sequence 1101110 with 101
    long original = 0b1101110;
    long prependee = 0b101;
    long prepended = original | (prependee << 7);
    System.out.println(Long.toBinaryString(original) + " -> " + Long.toBinaryString(prepended));
  }

  private static void appending() {
    // Appending the bit sequence 01110001 with 011
    long original2 = 0b01110001;
    long appendee = 0b011;
    long appended = original2 << 3 | appendee;
    System.out.println(Long.toBinaryString(original2) + " -> " + Long.toBinaryString(appended));
  }

  private static void changeBitSequence() {
    // Changing the bit sequence 11(010)11 to 11(100)11
    long unchanged = 0b1101011;
    long newValue = 0b100;
    // Create a mask that selects the parts that need to remain
    long mask = 0b1100011;
    // Clear part to be changed
    long changed = unchanged & mask;
    // Apply new value
    changed |= (newValue << 2);
    System.out.println(Long.toBinaryString(unchanged) + " -> " + Long.toBinaryString(changed));
  }

  private static void inserting() {
    // Inserting a '1' in between bit sequence 110011010 to become 110(1)011010
    long uninserted = 0b110011010;
    // Mask to select first part
    long mask1 = 0b111000000;
    // Mask to select second part
    long mask2 = 0b000111111;
    // Create a gap
    long tmp1 = ((mask1 & uninserted) << 1) | (mask2 & uninserted);
    // Add the value 1000000
    long inserted = tmp1 | (1L << 6);
    System.out.println(Long.toBinaryString(uninserted) + " -> " + Long.toBinaryString(inserted));
  }
```

## Network Layers
![layers]({{ site.url }}/images/network_layers.png)
* Each layer is a "level of abstraction"
  * Provides "services" to the layers above and below
  * Create the illusion of direct communication (horizontal line between same level layers), but in reality the information goes down from the origin up to the destination
![illusion]({{ site.url }}/images/illusion_direct_communication.png)
  * Only the lowest layer is the one that does the actual communication
  * Middle layers on different machines can have totally different service implementations, we dont care as long as the message is unchanged

### Open Systems Interconnections (OSI) Model
* This "model" divides the internet to diverse protocols (illusory direct communication between layers)
  * Each protocol is assigned to each layer

1. **Physical Layer** (lowest layer): Sends one bit via a physical medium, called a link
  * such physical medium can be an (ethernet) cable or a Wifi frequency
2. **Data link layer**: Sends a sequence of bits over a link *reliably*.
  * The pysical layer has a lot of errors (1 gets flipped into a 0 or viceversa or some data is lost during transmission). This layer deals with these errors so that the next layer doesnt even notice them.
    * **The MAC-Sublayer** regulates shared access to a (physical) medium, such as a wifi router. When multiple users are using a router, this sublayer manages how it is shared so that everybody can use it in a fair manner. MAC = medium access control
3. **Network layer**: Such as a LAN network or even the entire internet. This layer executes the sending of data from a source to a destination, which might be on the same network or on a different network.
4. **Transport layer**: The network layer has similar problems as the physical layer, where data is corrupted or lost, but at a higher level (i.e. sockets rather than single bits). This layer manages these problems and either decides to fix them or to ignore them (such as in a live videocall, where you do not want longer delays and rather have a potato but fast frames per second rather than HD frames per minute...). This is layer and upward ones only exist on the end hosts machines (i.e. the router has no longer nothing to do with). Therefore the source and destination only receive inderect feedback in the form of whether the packages have been received or not.
5. **Aplication layer** (highest level): These are protocols that deal with sending application specific information (email, web, instant messaging, games...)
  * The original OSI model actually has 2 additional layers between transport and application layer (5. Session and 6. Pressentation), but have no dedicated protocols and in practice the roles of these layers have been merged into either transport or application layers.
![communication]({{ site.url }}/images/communication_between_machines.png)
* Host stands for both source and destination parties
  * The data that a host sends is first forwared to the lowest layers on its machine (network, data link, physical)
  * Each of these apply some "preparing" tasks if needed, then send to the router, which then sends the data to another router (who may send it to another one and so on until reaching the destination router), who will pump the information up to the higher layers who will forward it to the correct application layer. (i.e. whatsapp messages should be sent to the whatsapp app used by the phone with the corresponding local IP address)

### TCP/IP model
* Whereas the OSI model (especially the original one that included Session and Presnetation) is a platonic model of what the ideal communication layers would look like, the TCP/IP model looked at the protocols that exist in practice and based on the ones being used it came up with:
![tcpip]({{ site.url }}/images/tcpip.png)
* It is practically the same but it officially removes the presentation and session layers, renames Network for Internet, and merges Data link and Pysical into Host-to-network (sometimes called the link layer). The reason of the merging is because even though OSI initially let each layer to be implemented independently, the wifi (pyhisical) was so irreliable that it was easier to enforce that all wifi layers are uniformly consistent with the data link layer so that errors are more intuitive and easier to handle.

![protocols]({{ site.url }}/images/protocols.png)

* TCP is reliable and connection-oriented
* TCP handles flow control
* UDP is unreliable and connection-less oriented

### Units of data
![404]({{ site.url }}/images/units_of_data_per_layer.png)
* The link layer wraps all the units of data, and the rest of the layers wraps those above, like a matrioshka:
  * Data link layer uses frames
  * Network layer uses packets
  * Transport layer uses segments
  * Application layer uses ???

## Error Detection
### Parity bits and checksums
* Checks for errors in the network. Possible causes are:
  * Errors between the client side wifi router and the machine
  * Errors in one of the multiple wifi routers on the server side
* Possible types of errors:
  * Bit could be flipped
    * Bit flip algorithms
  * Truncated/lost bits
    * Solution: Sender and reciver keep track of how much quantity they have sent and received

### Error Detection
1. Receipient detects an error
2. Recipient tells sender that error has been found, requests resend
3. Sender has to resend the data

### Error correction
1. Recepitent detects an error
2. Recipient is smart enough to fix it on its own

Both detection and correction are only possible by adding extra information to the messages which can allow to detect for errors.

Detection increasesy accuracy but increases latency and band-width usage whereas correction does the opposite.

* Just detection and request retransmission is preferred over cable connections as the the errors appear much less frequently than in wifi connections and the occasional double request is offset by having less overhead.
* For wireless connections errors are much more frequent and double-requests would be too expensive, therefore error-correction is prefrerred.

### Parity bits
* A binary sequence has either even or odd parity (if it has an even/odd number of 1s)
* Parity bit algorithm: Sender and receiver agree on a fixed parity for all messages
  * Sender adds bit to message to get desired parity (appended to the right)
  * If parity is different then message must have been corrupted (however, keeping the same parity does not guarantee a successful message)
  * Algorithm can only detect odd number of bit flips

### Checksum
* Divides bits into groups of k-bits. Assume k=4.
* Computes the binary sum (bitwise xor) of all the blocks (carried over bits are ignored)
* Appends the sum to the recepient
* The bitwise sum of the recepient which includes the appended sum should be all zeros (111 XOR 111 = 000), if not, then there was an error

### Checksum in 1s complement
* It's the same but in the XOR addition add a row of all 1's.

![checksum1]({{ site.url }}/images/checksum1.png)

* The receiver should get all 1's when adding the checksum


### Hamming distance
To be able to detect or correct an error in a transmission, the data needs to have redundant information. This extra data can be used by the receiver to check if the original data has changed during the transmission and possibly correct the error. A piece of data together with its redundant information is called a codeword. Given an algorithm for computing the (redundant) check bits, it is possible to construct a set of all valid codewords, which is called a code.

**The Hamming distance is used to count the number of bit positions that two codewords differ.** To compute the Hamming distance of an entire code, you need to find **the smallest Hamming distance between all combinations of valid codewords in the code**.

For example:
```
Code = {0000, 0011, 1100, 1111}
distance(0000, 0011) = 2
distance(0000, 1100) = 2
distance(0000, 1111) = 4
distance(0011, 1100) = 4
distance(0011, 1111) = 2
distance(1100, 1111) = 2
```
Therefore Hamming Distance = 2



The error-detecting and error-correcting properties of a code depend on its Hamming distance. **To reliably detect d errors, you need a code with a minimal distance of `d + 1`** because with such a code there is no way that d single-bit errors can change a valid codeword into another valid codeword. When the receiver sees an illegal codeword, it can tell that a transmission error has occurred.

Similarly, **to correct d errors, you need a code with a minimal distance of `2d + 1`**. If all legal codewords differ in at least `2d + 1` bits, a codeword with at most d changes is still closer to the original codeword than any other codeword. This means the original codeword can be uniquely determined based on the assumption that d is in indeed the maximal number of errors.

* The number of bits in a codeword is case specific and may or **may not** have the same number of bits as an assembly `WORD`.

```java
class HammingDistance {

  /**
   * Calculates the hamming distance of the given code, or returns -1 if it cannot be calculated.
   *
   * @param code The code, consisting out of a list of codewords
   * @return The hamming distance of the given code , or -1 if it cannot be calculated
   */
  static long calculate(List<Long> code) {
    Long min = Long.MAX_VALUE;
    

  for (Long currentWord : code){
    for (Long otherWord : code){
        if (currentWord != otherWord){
                long xor = currentWord ^ otherWord;
                long count = Long.bitCount(xor);
          if (count < min){
            min=count;
          }
        }
    }
  }
  return min == Long.MAX_VALUE ? -1 : min;
  }
}
```

### Cyclic Redunancy Check (CRC)
* Long division with remainder for binary numbers Uses a polynomial interpretation for each of the digits of a number, therefore there is like addition with no carryover (at all)
  * \\(x^3+x^2+x+1\\)

![binary_division]({{ site.url }}/images/binary_division.png)
* The data is the numerator and "error" is the denominator (different errors can find different amount of flipped bits)
  * CRC cannot detect any errors where the error is a multiple of generator
* The error denominator (aka generator) is chosen such that the remainder is 0
* When the receiver computes the division, if the remainder is not zero then it has detected an error
* There can be undetected errors if the changed bits come from the data + multiple of error

![crc_fn]({{ site.url }}/images/crc_fn.png)

* CRC is a very common error detection scheme, which is used in the Ethernet protocol
* it’s not secure against deliberate attacks
* If we want to send our own sequence of bits, just divide it by the generator and append the result to the right of your sequence
  * Keep in mind that you have to append 0's always to the bit sequence before dividing it such that the appended block length is equal to the number of bits in the generator - 1. These appended bits are called "frame check sequence".

```python
from library import bit_count

class CRC:

    @staticmethod
    def calculate(bit_sequence: int, input_length: int, generator_sequence: int) -> int:
        """
        Calculates the CRC check value.

        :param bit_sequence: The input bit sequence.
        :param input_length:  The length of the input bit sequence (including possible leading zeros).
        :param generator_sequence: The generator bit sequence.
        :return: The CRC check value.
        """
        
        gen_length = len(format(generator_sequence, "b"))
        
        bit_sequence <<= gen_length - 1
        input_length += gen_length - 1
        
        for shift in range(input_length - 1, gen_length - 2, -1):
            print(format(bit_sequence, "b").zfill(input_length))
            if bit_sequence >> shift:
                bit_sequence ^= generator_sequence << (shift - gen_length + 1)
        
        return bit_sequence


    @staticmethod
    def check(bit_sequence: int, input_length: int, generator_sequence: int, check_sequence: int) -> bool:
        """
        Checks the correctness of the bit sequence.

        :param bit_sequence: The CRC bit sequence excluding the CRC check value
        :param input_length: The length of the input bit sequence (including possible leading zeros)
        :param generator_sequence: The generator bit sequence used
        :param check_sequence: The CRC check value to check against
        :return: True if the sequence is correct, False otherwise
        """
        
        return CRC.calculate(bit_sequence, input_length, generator_sequence) == check_sequence
```

### Hamming code (n+k,n)
<iframe width="100%" height="415" src="http://www.youtube.com/embed/373FUw-2U2k" frameborder="0" allowfullscreen></iframe>
* Like the previous techniques were extra bits provide information that allows an algorithm to correct certain errors. Hamming Codes have two numbers:
  * n: bit length of the original data/message (d3 = data bit 1)
  * k: number of extra bits and their parity (the size of k is determined by n) (p1 = parity of slot 1)

Example: 10011010

a. Sender allocates n+k slots and enamurate the slots from the left starting at 1.

| p1| p2| d3| p4| d5| d6| d7| p8| d9|d10|d11|d12|
|---|---|---|---|---|---|---|---|---|---|---|---|
|   |   |   |   |   |   |   |   |   |   |   |   |

b. The sender copies the n-bit message into slots that are NOT powers of two.

| p1| p2| d3| p4| d5| d6| d7| p8| d9|d10|d11|d12|
|---|---|---|---|---|---|---|---|---|---|---|---|
|   |   | 1 |   | 0 | 0 | 1 |   | 1 | 0 | 1 | 0 |

c. The other slots have the parity of a sequence of bits, depending on the position of the parity bit.
   *  p1 checks the parity of odd numbers, and converts itself to 1 or 0 to keep the XOR sum = 0
      *  p1+1+0+1+1+1=p1+0, p1=0

| p1| p2| d3| p4| d5| d6| d7| p8| d9|d10|d11|d12|
|---|---|---|---|---|---|---|---|---|---|---|---|
| 0 |   | 1 |   | 0 | 0 | 1 |   | 1 | 0 | 1 | 0 |

  * p2 checks 2 bits, skip 2 bits, formally checks the parity of binary numbers whose second bit is "ON", i.e. 00**1**0,00**1**1,01**1**0,01**1**1,10**1**0,10**1**1,11**1**0,11**1**1=(2,3,6,7,10,11,14,15)
    * p2 = p2+1+0+1+0+1=p2+1,p2=1

| p1| p2| d3| p4| d5| d6| d7| p8| d9|d10|d11|d12|
|---|---|---|---|---|---|---|---|---|---|---|---|
| 0 | 1 | 1 |   | 0 | 0 | 1 |   | 1 | 0 | 1 | 0 |

  * pn checks the parity of binary numbers whose k bit is "ON"...
  * p4 is k-bit number 3, so 100,101... =  4,5,6,7,12,13,14,15
    * p4+0+0+1+0=p4+1,p4=1

| p1| p2| d3| p4| d5| d6| d7| p8| d9|d10|d11|d12|
|---|---|---|---|---|---|---|---|---|---|---|---|
| 0 | 1 | 1 | 1 | 0 | 0 | 1 |   | 1 | 0 | 1 | 0 |

   * p8 is k-bit number 4 so 8-15, 24-31...

| p1| p2| d3| p4| d5| d6| d7| p8| d9|d10|d11|d12|
|---|---|---|---|---|---|---|---|---|---|---|---|
| 0 | 1 | 1 | 1 | 0 | 0 | 1 | 0 | 1 | 0 | 1 | 0 |

d. Receiver flips those bits whose parity doesnt match
* error at d10

| p1| p2| d3| p4| d5| d6| d7| p8| d9|d10|d11|d12|
|---|---|---|---|---|---|---|---|---|---|---|---|
| 0 | 1 | 1 | 1 | 0 | 0 | 1 | 0 | 1 | **1** | 1 | 0 |

* Manually check the parity of all parity bits again
  * p2 is flipped
  * p8 is also fipped
  * 2+8=10, d10 is the bad bit

### Parity block
#### Sender
* Arrange the message in r by c bits matrix
* Compute the parity bits for all rows and columns respectively
* The corner bit is the parity of all bits, it has the same parity as the row and the column parity bits

![parity_block]({{ site.url }}/images/parity_block.png)
#### Receiver
* Assumes there was at most one bit flip
* Computes the parity bits for all rows and columns and finds the coordinates of the flipped bit and flips it

![fix_block]({{ site.url }}/images/fix_block.png)

* We can use the column/rows bit and corner bit to check if the flip was in the appended parity bits rather than in the data. These may be fixed depending on whether we forward these parity bits or not.

### Overhead Analysis
* Overhead: amount of extra information required by protocol in comparision to actual data
  * If for 100byte of data you have 1byte of appended information then you have a 1% overhead with O(n)
* Parity blocks have an overhead of r+c+1 bits
* Use derivative to minimize overhead

![fix_block]({{ site.url }}/images/overhead.png)

* This has asymptotic complexity of \\(O\sqrt{n}\\)
* Hamming Code has n+k bits overhead
* The asymptotic complexity is \\(O(log(n))\\)

![fix_block]({{ site.url }}/images/hc_overhead.png)

* Both parityblocks and hamming code can only correct 1 bit flip. There are other algorithms that can flip more bits, but none of the standard network protocols use them.

### Burst Errors
* Errors typically occur in bursts, so if one bit is flippied there is a high probability the next one is flipped as well
* We can mitigate error bursts by arranging the data in columns and rows and assigning a sepearate hamming code algorithm to teach column and row, which then only has to handle 1 flipped bit at a time

## Services
![service]({{ site.url }}/images/service.png)
* Ethernet does not provide reliable communication (acknowledged).
  * It is up to higher protocol levels to recover from this problem.
* In real-life application unreliable communication is prefered because of speed and flow
* For file transfer reliable is imprescindible.

### Connection-Oriented service
* Communication between layers based on the telephone system. To talk
to someone, you pick up the phone, dial the number, talk, and then hang up.
 * To use a connection-oriented network service, the service user first establishes
a connection, uses the connection, and then releases the connection.
* The
essential aspect of a connection is that it acts like a tube: the sender pushes objects
(bits) in at one end, and the receiver takes them out at the other end.
* In some cases when a connection is established, the sender, receiver, and subnet
conduct a negotiation about the parameters to be used, such as maximum
message size, quality of service required, and other issues.
* Typically, one side
makes a proposal and the other side can accept it, reject it, or make a counterproposal.
* A circuit is another name for a connection with associated resources,
such as a fixed bandwidth.

### Connectionless service
* Communication between layers based on the postal system.
* Message carries full destination address
* each one is routed through the intermediate nodes inside the system independent
of all the subsequent messages
  * a packet is a message at the network layer.
    * When the intermediate
    nodes receive a message in full before sending it on to the next node, this
    is called store-and-forward switching. The alternative, in which the onward
    transmission of a message at a node starts before it is completely received by the
    node, is called cut-through switching. Normally, when two messages are sent to
    the same destination, the first one sent will be the first one to arrive. However, it
    is possible that the first one sent can be delayed so that the second one arrives
    first.

### Reliable service
* having the receiver acknowledge the receipt of each message
so the sender is sure that it arrived. The acknowledgement process introduces
overhead and delays, which are often worth it but are sometimes undesirable.

### Connectionless application
* All that is needed is a way to send a single message that has high probability of arrival but no guarantee nor acknoweldge is returned to the sender. This is often called a datagram service.

### Acknowledged datagram
* acknowledged
datagram service can be provided for these applications. It is like sending a registered
letter and requesting a return receipt.
* When the receipt comes back, the
sender is absolutely sure that the letter was delivered to the intended party and not
lost along the way.
* Text messaging on mobile phones is an example.

### Request-reply service
* In this service the sender
transmits a single datagram containing a request; the reply contains the answer.
Request-reply is commonly used to implement communication in the client-server
model
  * the client issues a request and the server responds to it.

## Data link layer
* The data link layer uses the services of the physical layer to send and receive
bits over communication channels. It has a number of functions, including
  1. Providing a well-defined service interface to the network layer.
  2. Dealing with transmission errors.
  3. Regulating the flow of data so that slow receivers are not swamped
by fast senders.
* To accomplish these goals, the data link layer takes the packets it gets from the
network layer and encapsulates them into frames for transmission. Each frame
contains a frame header, a payload field for holding the packet, and a frame
trailer.

![frame]({{ site.url }}/images/frame.png)

### Services Provided to the Network layer
* The function of the data link layer is to provide services to the network layer.
  * transferring data from the network layer on the source machine
to the network layer on the destination machine

#### Unacknowledged connectionless service
* having the source machine
send independent frames to the destination machine without having the
destination machine acknowledge them. suchas Ethernet.
* No logical connection is established beforehand
or released afterward.

#### acknowledged connectionless service
* there are still no logical connections used, but
each frame sent is individually acknowledged.
* the sender knows
whether a frame has arrived correctly or been lost. If it has not arrived within a
specified time interval, it can be sent again. This service is useful over unreliable
channels, such as wireless systems. 802.11 (WiFi) is a good example of this class
of service.
* On
reliable channels, such as fiber, the overhead of a heavyweight data link protocol
may be unnecessary, but on (inherently unreliable) wireless channels it is well
worth the cost.

#### connection-oriented service
* the source and destination machines establish a connection before any data are
transferred.
* Each frame sent over the connection is numbered, and the data link
layer guarantees that each frame sent is indeed received.
* it guarantees
that each frame is received exactly once and that all frames are received in
the right order
* provides the network layer processes
with the equivalent of a reliable bit stream.
* transfers go through three distinct
phases:
  * In the first phase, the connection is established by having both sides initialize
variables and counters needed to keep track of which frames have been received
and which ones have not.
  * In the second phase, one or more frames are actually
transmitted.
  * In the third and final phase, the connection is released, freeing
up the variables, buffers, and other resources used to maintain the connection.

## Data link layer framing
* The main responsibility of the data link layer is to provide reliable transport of bits.
  * To achieve that it uses error detection or error correction
    * You dont apply that on the entire file, you do it in "frames"

![frame2.png]({{ site.url }}/images/frame2.png)

* Ethernet damaged cables have occasional data loss just as wifi connected devices far from the wifi range.

### How to determine start of a frame
* Break between frames
  * But: telling breaks from lost bits is impossible & several parties using the medium can cause interference and mask breaks.
* Fixed length frames
  * But hard to tell which frame is damaged

Therefore:
1. Only rely on data rather than on assumptions about speific properties of the medium (such as ability to detect breaks)
2. Use an algorithm so that data loss only has consequences for the affected frames

#### Byte Stuffing: Flag determines beginning and end of the frame.

![bs.png]({{ site.url }}/images/bs.png)

![bs2.png]({{ site.url }}/images/bs2.png)

![bs3.png]({{ site.url }}/images/bs3.png)

![bs4.png]({{ site.url }}/images/bs4.png)

* Escape byte is a byte that indicates that next byte should be treated like normal data and not as a special character.
  * The escape byte also needs to be escaped

![bs5.png]({{ site.url }}/images/bs5.png)

![bs6.png]({{ site.url }}/images/bs6.png)

* Disadvantage: a lot of overhead due to escape bytes

* Alternative, Bit stuffing:

![bs7.png]({{ site.url }}/images/bs7.png)

![bs8.png]({{ site.url }}/images/bs8.png)

#### Dealing with lost frames: Automatic Repeat ReQuest (ARQ) for noisy channel uses acknowledgement
  * Receiver acknowledges frames that are correctly delivered
  * Sender sets timer and resends frame if no ack
  * If there is no acknowledgement (timeout) then sends the frame again
  * It can be the rare case when there is no acknowledgement wihin the timout but it has indeed been sent (it's just slow) then you'd have a duplicated frame

![arq.png]({{ site.url }}/images/arq.png)

* Frames and acknowledgements must be numbered to fix the duplicated issue
* The problem of sop and wait is that it wastes a lot of bandwidth by waiting

#### Sliding windows
* The technique of temporarily delaying
outgoing acknowledgements so that they can be hooked onto the next outgoing
data frame is known as piggybacking.
The principal advantage of using piggybacking over having distinct acknowledgement
frames is a better use of the available channel bandwidth.
* This is something different to the images below, what it means is that in a 2-way communication where A and B both are poractively talking, instead of wasting one dummy frame for just the ack, add the ack into the header of the next frame containing real data.
* However If the data link layer waits longer
than the sender’s timeout period, the frame will be retransmitted, defeating the
whole purpose of having acknowledgements.
* Therefore, If
a new packet will be sent quickly, the acknowledgement is piggybacked onto it.
Otherwise, if no new packet will be sent by the end of this time period, the data
link layer just sends a separate acknowledgement frame.

Real sliding windows:

* The essence of all sliding window protocols is that at any instant of time, the
sender maintains a set of sequence numbers corresponding to frames it is permitted
to send.
  * These frames are said to fall within the sending window.
  * Similarly,
the receiver also maintains a receiving window corresponding to the set of frames
it is permitted to accept.
* Since frames currently within the sender’s window may ultimately be lost or
damaged in transit, the sender must keep all of these frames in its memory for
possible retransmission. Thus, if the maximum window size is n, the sender needs
n buffers to hold the unacknowledged frames

![sn.png]({{ site.url }}/images/sn.png)

![sn2.png]({{ site.url }}/images/sn2.png)

![sn3.png]({{ site.url }}/images/sn3.png)

![sn3.5.png]({{ site.url }}/images/sn3.5.png)

![sn4.png]({{ site.url }}/images/sn4.png)

#### Example

![swq.png]({{ site.url }}/images/swq.png)
![swa.png]({{ site.url }}/images/swa.png)
![swa2.png]({{ site.url }}/images/swa2.png)
![swa3.png]({{ site.url }}/images/swa3.png)


## MAC Sublayer
* The main purpose of the MAC Sublayer is to allow multiple parties to share a medium or a small local network.

### Channel allocation protocols
*  protocols run on the sender side that determine when it's the sender's turn to use a shared medium.

### ALOHA
* Users transmit frames whenever they have data
* if collision occurs, retry after a random delay
* does not scale well

![aloha.PNG]({{ site.url }}/images/aloha.PNG)

![aloha2.PNG]({{ site.url }}/images/aloha2.PNG)

![aloha3.PNG]({{ site.url }}/images/aloha3.PNG)

![aloha4.PNG]({{ site.url }}/images/aloha4.PNG)

### Carrier-Sense Multiple Access (CSMA)
* Senders can detect (sense) if the channel is in use
  * 1-persisten: wait for idle, then send
  * Nonpersistent: if busy, wait random amount of time and try again
  * p-persistent: if busy, wait for next slot, if idle, send with probability p

### 1-persistent
![1p.PNG]({{ site.url }}/images/1p.PNG)

* problem: if parties send it at the exact same time, they will resend at same time and have collision again.

### Nonpersistent CSMA
![np.PNG]({{ site.url }}/images/np.PNG)

* instead of immedeatly resending, it randomly waits before sending again.
* problem: the channel is unitilized often

### p-persistent
* compromise between 1-persistent and nonpersistent
* the higher the p, the closer it gets to 1-persistent (higher probability of collisions)

![pp.PNG]({{ site.url }}/images/pp.PNG)

### Channel utilization comparision
* As the load increases the utilization of the channel decreases due to an increased collision probability (poisson distributed)

![ch.PNG]({{ site.url }}/images/ch.PNG)

* Being greedy gives good performance under low load
* Being generous gives good performance under high load

### CSMA with Collision Detection (cable)
* The other CSMA do of course know when a frame has been collided (carrier sense is the ability to detect if a medium is being used).
* But Collision detection aims to detect a collision while the medium is being used, not just after an acknoweldge timeout, so that we can abort the transmission and saves time and bandwidth.
* To do so the devices must be able to send and listen at the same time. With Ethernet is possible but with Wifi it is not, as sending is 1M times stronger than listening frequencies, hence interfering with what it could potentially be heard.
* we can think of CSMA/CD contention as a slotted
ALOHA system (for the listening part) with a slot width of 2 delta (delta being the propagation delay from one device to another).

![ct.PNG]({{ site.url }}/images/ct.PNG)

![cs.PNG]({{ site.url }}/images/cs.PNG)

* Transmission starts when there is only one party sending

![cd.PNG]({{ site.url }}/images/cd.PNG)

### Collision-free protocols
* Usueful in very controlled environments, but not for general environments.

#### Token ring
![tr.PNG]({{ site.url }}/images/tr.PNG)
* You can add new stations into the ring

#### Bit-map protocol
* Assumption: Static and known stations with common notion of slots
* Contention slots are N
* Algorightm: Enumerate stations
  * In contention period, each station is assigned a slot to transmite the bit 1 if they want to send something
  * In tramsission period, all stations that indicated they want to send, send one frame.
  * The order in which the frames are sent is already hardcoded in the algorithm for each station.

![bm.PNG]({{ site.url }}/images/bm.PNG)

#### Binary countdown
* Assumption: Static and known stations with common notion of slots
* Contention slots are ceil(log N)
* Algorightm: Stations have distinct priorities
  * Collision results to binary OR of bits sent at the same time
  * Stations express their priority as binary numbers
  * When a station wants to send, it send bits of priority starting at the most significant bit (left)
  * If 1 is received when 0 was sent, then the station stops and waits for new round
  * The one with the highest priority will send the next frame

![bc.PNG]({{ site.url }}/images/bc.PNG)

### Multiple access with collision avoidance (MACA) (wireless)
* Having wireless channels removes the need for wires (which is good), but it does make it harder to detect collisions (which is bad).
* MACA stands for multiple access with collision avoidance (as opposed to collision-free, here there are no guarantees)
* Terminals (stations for wireless networks) have a range. Their transmissions are only received by parties within the range.

![range.PNG]({{ site.url }}/images/range.PNG)

![macasense.PNG]({{ site.url }}/images/macasense.PNG)

![htp.PNG]({{ site.url }}/images/htp.PNG)

![etp.PNG]({{ site.url }}/images/etp.PNG)

* MACA mitigates the hidden node problem and exposed node problem through two extra messages (request to send and clear to send)
* Protcol
  * Request-to-send (RTS):
    * Indicate to terminal that you want to send and include sender (you) and receiver MAC address 
  * Clear-to-send (CTS):
    * Indicate receiver that the terminal is free to receive frames (if it is not receiving anything else)
    * Include address of receiver
  * Sender sends frame to receiver
  * Receiver sends acknowledge back
  * Terminals in the range of the CTS will behave and stop sending anything until A sends an acknowledge or a timeout
  * A will back off before sending another RTS if it does not receive CTS

* In the event that 2 terminals RTS a third terminal at the same time, this one doesnt receive a proper RTS due to interference. Each of them will try again at randomly different times.
* The exposed terminal node problem is solved only when the RTS and CTS happen simulatenously, when they happen with one step offset the CTS of the second gets interfered with the frame from the first one.

## Ethernet
* Used for wired internet
* Uses 1-persistent CSMA/CD because there is not too many parties using the medium.
  * The random backoff is binary: Choose number of slots uniformly at random in {0,1,3,7,...,2^i-1} where i is the number of failed tries to send the rame.

![ef.PNG]({{ site.url }}/images/ef.PNG)

* Header:
  * The preamble (or preabmle + SoF) contains 7 bytes with 1010 1010 and the last one with 1010 1011
  * The destination address and source address are the MAC addresses (basically the hardware unique address of the receiver and the sender)
  * Type contains the upper layer protocol used. Turned out it was not effecient to just have that field.
  * Length contains length of frame in bytes, which allwos the receiver to split the frames without knowing the data
* Payload:
  * Data must have a minimum length of 72B, if not reached its padded automatically.
  * Padding: This is due to the propagation delay (easier when the length has a min size for collision detection calculations). When detecting a collision, station warns other by 48 bit noise burst.
* Trailer:
  * Checksum

![ep.PNG]({{ site.url }}/images/ep.PNG)

## Wifi (802.11 standard)
* A device cannot send and listen to frequencies at the same time, as the act of sending will interfere with what could be listened.
* Devices can only rely on ACKs to determine if collision ocurred
* Wifi uses MACA with carrier sense avoidance: CSMA/CA

![csma.PNG]({{ site.url }}/images/csma.PNG)

![macvs.PNG]({{ site.url }}/images/macvs.PNG)

![wififrame.PNG]({{ site.url }}/images/wififrame.PNG)

## LAN
* MAC addresses are used to identify the receiver

![lan.PNG]({{ site.url }}/images/lan.PNG)

### Hub
* Extension of the phyisical layer, its a device that connect multiple Ethernet devices.
* The signal from the input/output ports is extended to all other ports, making all the cables act as one single long cable

### Switch
* As opposed to a hub where the entire signal is forwared to all the devices, the switch uses mac addresses to forward frames only to the intended destination
  * Use backwards learning data structure
    * Frames have source and destination address
    * Switch keeps a hash table that maps addresses to port numbers
    * First time a device sends a frame the switcher can already assign a port to the sender device
    * Switch broadcasts frame to all other devices
    * When device replies back to the frame the switch can map the responding device
    * Devices move and hence change port. Switcher keeps track of "last seen" time for each MAC address. Periodically remove old addresses (a minute or so).
* This one acts on the datalink layer (rather than on the physical link layer like the hub)

![redundancy.PNG]({{ site.url }}/images/redundancy.PNG)

* However it can end up on an infinite loop if the receiver is never found. Which would bring the network down
* **Spanning tree**: To fix the infinite loop problem we only use a minimal subset of cables and leave the others as backups

![st.PNG]({{ site.url }}/images/st.PNG)

* If a cable fails, the nodes will look for a different parent, if the parent of a node fails, two things may happen, the child doesnt notice it fast enough, so it keeps the same parent (as the parent managed to fix the connection), or the child re-routes via a different parent that is connected to the route.

## Network layer
* Remember that the data link layer operates only when you have a shared channel (i.e. a wave frequency, an ethernet cable)
  * You have to create frames from bits/bytes (head, load, trailer, checksum...)
  * You have to detect/correct transmission errors (CRC...)
  * You have to efficiently use the avaible bandwidth between machines (ALOHA, collision avoidance/detection etc)
* The network layer already assumes that the datalink layer works and members can talk to each other
  * The (routing, transprt) network layer will forward your messages everywhere it can
  * The network layer will manage network congestion
  * The NL is responsible for customer service
  * The NL connects multiple networks

"It takes charge of how the network looks and how to get messages through"

* The network layer is the heart of the networking model, together with the transport layer
* OSI layers below (data link layer, physical layer) do not know about end-to-end delivery (they just put the message in a medium, where everybody is listening)
* OSI layers above do not know about the topology of the network
* Both layers above and below do not know about routing (in theory)

* Only ISP (internet service provider) companies, or companies that sell ISP services, can own an IP address, the rest of users can only rent fixed IP addresses. Dynamic addresses are included by default in any internet subscription.

* The network layer provides unique (IP) addresses to the transport layer
* Internet is linked to politics, i.e. Isreal doesnt exist in Dubai, China firewall google, etc. So there's not an universal routing.
* Nevertheless, the network layer stands for the global network 
  
![404]({{ site.url }}/images/2services.PNG)

### The connection-less model
* Dominant choice
* Routers use algorithms to decide where to send each packet individually every time
  * This model scales better than the telephone network model where 1 big lookup table had to be checked by all the users
  * This model routes each packet and gives it individual attention
* Used by the Internet Protocol (IP)
* Deals with congestion better than connection-oriented service

### Connection-oriented service
* Makes virtual circuits
* When conenction is made, fixed route is decided
* All packets follow the same route
* ISPs sometimes use this on top of IP
* The route needs to be neogitated in advance, together with bandwidth and other paramaters

![404]({{ site.url }}/images/servicescompared.PNG)

## Routing
* How to move packets around the world
* Routing properties (they constitute trade-offs often):
  * Correctness
  * Simplicity
  * Robustness
  * Stability
  * Fairness
  * Efficeny
* Traffic engineers optimize routes between points. If the best route between A and C goes through B, then we know that the the route from B to A is preciesly a subset of such route.
* The collection of all best paths to a given destination is known as a tree

### Routing tables
* You want to know for every address on which link to forward the packet (so cartesian product of all addresses...) look up table. The cost could be distance.

![404]({{ site.url }}/images/rt.PNG)

* Routes get updated and oveloaded
* Need to keep it updated

### Distance vector routing
  
1. Send your distance vector to your neighbors.
2. You use incoming distance vectors from your neighbor to construct a routing table. ![404]({{ site.url }}/images/routingtable.PNG)
3. The distance vector of A might be different than the old one existing in the routing table. Therefore A updates the routing table.
   1. If routers are faulty then you're screwed (i.e. by relying on outdaded wrong tables)
   2. Count to infinity problem when machine fails: A machine who previously had a cost of 1 to that machine, will get 9999...., then will just go through another node, but then the node at some point will realize that its previous work didnt work either, etc. then everything will be incremented by 1 continuously, until reaching 9999999....
   3. This happens because nobody has the overall picture

### Link state routing
* Link state routing does not suffer from the count to infinity problem, but it is more complicated.
* Uses shortest path algorithm:
  * Routers only send packets with information about their direct neighbors (information that they confirmed is correct)
  * These packets are flooded over the network (flooding is robust)
    * Need to give sequence numbers to the packets to distinguish between old and new. But you never know what the latest sequence number is, so what you have might be outdated. Therefore validity age is used as well.
  * Routers built an overview of the network using these packets and run a shortest path algorithm

![404]({{ site.url }}/images/lsr.PNG)

* Then we use Dijkstra

<iframe width="100%" height="415" src="http://www.youtube.com/embed/pVfj6mxhdMw" frameborder="0" allowfullscreen></iframe>

### Hierarchical routing
* Reduce the size by grouping nodes

![404]({{ site.url }}/images/hr.PNG)

### Congestion control

* Responsibility of both the network and transport layers

Types:

#### Prevent congestion by increasing available bandwidth
Self explanatory

#### Traffic aware routing
* Choose routes depending on traffic, not just topology

#### Admission control
* If theres' congestion, new traffic has to wait
* Can be combined with traffic aware arouting

#### Traffic throttling
* ISP deliberately slows down your speed due to high traffic
![404]({{ site.url }}/images/tt.PNG)

#### Load shedding
* Sacrifice packets for overloaded routers
* Wired links are reliable
  * Wireless link need to solve transmission errors on the data link layer to support this
* Packet loss likely caused by congestion
* Random Early Detection (RED) drops packets randomly if buffer space is almost full
  * Sends implicit signal to the sender: slow down!
  * Sender interprets packet loss as conegestion signal

## Internetworking
* Getting packets to their destination across multiple networks
* Networks may use different protocols
* Networks may offer different QoS guarantees
* Networks may have different maximum packet sizes

### Tunneling
* If the source and destination networks use the same protcols, we can use tunneling
  * There's an inbetween zone were both the entrance and exit routers are bilingual
  * These bilingual routers actually wrapp the packet into something their protocol understands and then unwraps it at the exit
* Cons: you cant debug the network as tools like ping dont work with the tunnel

### Packet fragmentation
#### Transparent fragmentation
* Packet size can be limited by hardware, software, protocols, law
* Too big packets are split into smaller packets, and then group together

#### Nontransparent fragmentation
* The router splits the package but then the receiver doesnt get it grouped back, it has to fix it himself

#### MTU discovery
* Router refuses to transmit the packet (so forces the source to split it) naturally the receiver will also have to group it back
* This used in IP protocol

## Internet protocols
### IPv4
![404]({{ site.url }}/images/ipv4.PNG)
* One network to unify everything
* Time to live tells for how long to keep the packet floating in the internet, when its time expires and it gets deeleted, a message is sent back (to the sender). This could be used for DDOS attacks
* Identification is kept among split packets
* IPv4 uses 32-bit addresses
* Written in dotted decimal notation
* 2^32 is around 4 billion addresses
  * This would create a huge routing table
  * Instead the internet is divided into subnets so that we reduce the routing table sizes using hierarchical routing

For TU Delft any IP address that match 37.60.x.y will be routed to them. (TUD owns that subnet)
![404]({{ site.url }}/images/ip.PNG)

* IP addresses with the same prefixes are compressed into one entry of the routing table (this is called route aggregation).

### Network Address Translation (NAT)
* Most people from nepal are behind 1 public IP address
* the NAT box gives internal IP addresses to those devices sharing 1 external IP address
* Since there is no more space in the IP header, to implement this we use the port number to distinguish among the machines sharing the external IP
* Now the problem is shifted to having 2^32 NAT boxes instead

### IPv6
* Many more address
* Simplified header (improves bandwitdth/latency)
* Easier to add options in the header
* Improved security support
* 2^128 addresses
* Slow adoption rate

### Internet control protocols
#### ICMP
* If something goes wrong, routers send these messages to senders
  * Destination unrecheable
  * Time exceeded - Used by the program traceroute
  * Echo and echo reply - used by the program ping
  * Router advertisment/solicitation

#### Address Resolution Protocol (ARP)
* ARP packet asks "who owns this packet?" with an ethernet desination address.
  * Allegedly only the owner replies saying "it's mine"

#### Dynamic Host Configuration Protocol (DHCP)
* A machine without an IP address requests to get one assigned
* Somewhere a DHCP server received the request and offers an avaiable address. (IT INCLUDES SUBMASK,  dns, GATWEAY ETC)

## Gateway protocols
### Routing in the internet
* Internet is made of Autonomous Systems (ASes), such as companies, universities, countries, ISPs
* Routing in the internet addresses:
  * Interoperability
  * political/economical policies of each AS
* Solution:
  * intradomain routing (routing packets inside AS) - interior gateway protocols
  * Interdomain routing (between AS) - exterior gateway protocols

### Open ShortestPath First (OSPF)
* Interior gateway protocol
* Routing within a (large) AS
* A form of link state routing
  * Builds a graph representation of the network
![404]({{ site.url }}/images/ospf.PNG)
* Shortest path algorithm is applied

Properties:
* Distance metrics may be measured as delay, physical distance, etc.
* Routers balance the load: communication load is split over routes of equal costs
* Dynamic: OSPF responds to routers crashing and changes the topology of the network accordingly
* Hierarchy: Uses areas to manage large networks
![404]({{ site.url }}/images/hy.PNG)

### Border Gatweay Protocol (BGP)
* Exterior gatweay protocol
* Routing between (large) AS
* Supports various policies of ISPs, companies or countries
![404]({{ site.url }}/images/aa.PNG)
* BGP uses distance vector routing
  * Combined with path vector protocol
* A route to a desination is a next hop router and a list of ASes
* Routing costs are not communicated
* An AS chooses a route using its own policies

## Transport layer
### Addressing and Connections
* Internet uses IP addresses for Network Service Access Points (ip forwards to transport)
* Internet uses ports for Transport Service Access Points (ports forward to application)
* The transport layer offers 5 primitives:
  1. Listen: waits for another process to contact him in the transport layer
  2. Connect: asks continuously if someone wants to connect at a specific port
  3. Send: The connection has been established and so data is sent.
  4. Receive: receive data over the established connection
  5. Disconnect: release the conenction by leaving the port.

* Transport layer wraps stuff into segments, which contains transport layer specific information, such as ports, sequence numbers, etc.
* TCP service (transport layer API) is obtained by both the sender and the receiver creating endpoints, called sockets (each socket has a socket number (address) consisting of the IP address of the host and a 16-bit number local to that host, called a port). In order to use a socket at one machine a connection with the socket at the other machine must have been established.
* The socket contains the following berkely socket primitives (used by TCP):
  1. Socket: creates a new communication endpoint
  2. Bind: assigns a local address to the socket
  3. Listen
  4. Accept: passively accepts an incoming connection request
  5. Connect
  6. Send
  7. Receive
  8. Close

TCP (Transport layer) binds the sockets inside the segments to the relevant application. This means that every application using the internet must be connected to a port. Constantly running applications connected to the internet will have an open port connection and that is a lot of processing power, that's why smartphones run out of battery that quickly (each app running in the background constitutes a separate port connection)

**process server** (to the rescue): instead of constantly running application connections that you dont use that often, you have a process server that looks up the incomming sockets, then after checking the port it will open the port and forward it to the relevant application only when necessary.

* If the application uses random ports (instead of the default i.e. mail, web,...) the process server doesnt know what to do with the socket.
* If the application is "live" it doesnt make sense to shut the connection on and off constantly.

### Segment Headers
* Segment is the unit of transfirmation of the transport layer
* It consist of a header 
  * Which has fields
* And a body
  * Actuall data

### User Datagram Protocl (UDP)
* Connection-less protocol on the transport layer
* Very thin layer on top of the IP. The header just provides ports needed to connect to remote applications
  * Source port & Destination port
  * UDP length & UDP checksum
* Despite having a checksum, UDP itself does not automatically retransmit in case of error
* It is up to the application to use the checksum to trigger retransmission.
* UPD is a good choice for avoiding the complexity of TCP while having the possibility of doing retransmission.
* There is no IP address in the header as that information is known by context since it is already available in the network packet IP header

### Transmission Control Protocol (TCP)
* Connection-oriented protocol
* Does have reliability by default (as opposed to UDP)
  * Error detection
  * Retransmission (automatic)
  * Flow control
  * Congestion control

* RFC = request for comment, published by the Internet Engineering Task Force (IETF)
* UDP: RFC 769 (a single one)
* TCP: RFC 4614 (this summarizes the many existing)
![404]({{ site.url }}/images/tcp.png)

* The vertical letters are flags (only a bit indicating 0 or 1)
* ACK = 1 means the message is an acknwoledge
* Sequence number, acknowledge number anc TCP checksum are used for error detection
* Window size is for flow control
* Header length determines the length of the header because as opposed to UDP where its fixed, TCP can add Option arguments (i.e. timestamps) which increase the length of the header.

For each TCP connection, local state consists of:
* Next squence nubmer to use
* Next acknowledgement number to use
* Congestion window
* Timers for retransmission
 
### TCP/UDP reliability measures
#### Checksum
* Both use checksum
* Routers may be drop packets due to congestion or misfunction
* Routers may flip bits
* UDP/TCP checksum divides data into 16-bit words
  * compute bitwise XOR over all words
  * Take one's complement of the result
  * For the receiver, if not all bits are 1, there was an error

#### Sequence numbers (of the TCP, not Data Link layer)
* Important in TCP. Not used in UDP
* Deals with lost data

Purpose of sequence sumbers:
* Detect missing segments
* Detect if segments arrive out of order
  * Due to routers with different latency
* Detect if parts of segments are missing
* Detect duplicates
  * It is up to the receiver to pick one

* Sequence numbers are 32 bits and stored in the TCP header
* SYN: connection establishment flag
* ACK: "this message is just an ack"
* FIN: connection termination flag
* These flags only need headers, so the body is often empty

* Before sending a SYN or after receiving a SYN a new squence number is established
  * initial own sequence number + number of previously sent bytes

* Acknowledgement number:
  * initial sequence number of communication partner + number of previously received bytes

* Use mod 32 bits when overflowing the numbers

* Every data byte adds 1 to the squence number
* SYN and FIN flags also add 1 to the squence number
* ACK does not increase sequence numbers

#### Initial sequence number
* 0 (and generally any constant number) is a bad idea due to delays and crashes
* If you start at 0, and then the router crashes, then when it restarts it will use the sequence number 0 again, and the receiver has the same sequence number but a different ack. Since they dont match, they will never manage to send data.

#### Clock-based sequence numbers
* Use the least significant 32 bits of clock time as initial sequence number
* TCP increases the sequence number at a slower rate than the clock speed

![404]({{ site.url }}/images/as.PNG)

#### Repeated squence numbers
![404]({{ site.url }}/images/rsn.PNG)
* Problem when there's a crash right before overlapping, this will confuse both sender and receiver just like in the 0 sequence number example. (incorrect duplicate detection)
* We use packet life time to deal with this together with forbidden regions (run a protocol that selects a new squence number for both parties)

![404]({{ site.url }}/images/rsy.PNG)

#### Modern TCP sequence number
* dont use clock-based sequence numbers because they are predictable and thus easy for an attacker to guess and impersonate a party in the communication
* modern TCP use randomized sequence numbers (you still need to resyncronize for the forbidden region problem)

### Establishing a TCP connection (Three-way handshake)
![404]({{ site.url }}/images/tcphs.PNG)

### TCP acknolwedgements
![404]({{ site.url }}/images/tcpack.PNG)

![404]({{ site.url }}/images/tcpack2.PNG)

### Duplicate ACK
![404]({{ site.url }}/images/dup.PNG)
![404]({{ site.url }}/images/fr.PNG)

* TCP as asliding window protocol uses selective repeat (3 duplicate acks = negative ack)
  * Instead of a number of k unack frames, TCP allows only for a lmited amount of data to be unack
  * Amount of data depends on current situation in network and on receiver's buffer size

### Crash recovery
* We cannot create fool-proof crash recovery in layer k. Memory loss on layer k makes it impossible to know if there is inconsisentency between sent acknolwedgement and forwarded data
* The application layer has to deeal with it

## Acknowledgements and error detection/correction differences between data link layer and transport layer

* We only error control at the data link layer and the transport layer.
* We need it on both datalink layer and transport layer because the two protect against different types of errors:
  * the data link layer deals with bitflips or lost data on a link (e.g., cable)
  * the transport layer deals with bitflips or lost data introduced by a device, most commonly a router
    * RED (Randopm Early Detection): a router randomly drops packets on the network layer to indicate congestion, which is something the error control of the data link layer cannot detect as it happens after the data link layer checks have been completed. That is why the transport layer also has error control (because of unreliable network routers)
  * Remember that altough the network layer (IPv4) packets have header checksums, it is seldom used by the ISP routers and it is officially discarded in IPv6 packets.


### Multiplexing
![404]({{ site.url }}/images/multiplexing.PNG)

## Difference between flow control and congestion control
* Flow control: To say the sender to slow down the speed so that the receiver can process the data. Receiver is bottleneck.
* Congestion control: The same but here the network is the bottle neck whereas the receiver has not problem with the speed.

## TCP Flow control
![404]({{ site.url }}/images/tcp.png)
* Window size (buffer) tells the sender how much data the recepient can handle
![404]({{ site.url }}/images/tcpws.PNG)
* If the sender keeps sending and the recepient hasnt had time to process the data then the window size decreases
![404]({{ site.url }}/images/wsd.PNG)
* Now sender will be quiet until the receiver has gained some buffer space for which the receiver will send another acknowledgement with the same number but with increased window size (it will not be interpreted as a duplicate acknowledgement as the window size is different)
* Very tiny window size will make the receiver to increase the overhead of the channel and waste bandwidth with a lot of acknowledgements for when the buffer has been restored. This is known as the silly-window syndrome.
  * Furthermore, by the time the ack has been sent, the actual buffer size might have increased, but the sender will send the old smaller size. This is inefficient as the receiver could have actually handle more and bandwidth is being wasted.
    * The slower the network the even more wasted the bandwidth is from the silly-window syndrome
* TCP in being conservative and making sure that the reciver can handle the data is sacrifying throughput. This is why some applications prefer to just use UDP and implement more efficient reliability algorithms on top of it.

## TCP congestion control
* Both network and transport layers are responsible for congestion control
* The network layer sends signals if there is congestion by dropping packets or routing them by a longer/less congested path
* The transport layer can arrange the amount of load that is added onto the network
![404]({{ site.url }}/images/congestion.PNG)
* While everything is going fine TCP will try to increase the bandwidth it uses
  * It will slow down as it receives a congestion signal

### Congestion signals
* Explicit feedback from routers (max amount, rare implementation)
* Loss (most common one)
  * Protocol RED (random early detection): drops packets as congestion happens and transport layer reacts accordingly
  * a delayed packet can be confused for a lost packet
* Latency (delays between received acks bigger than between sent segments)
  * Takes longer to calculate but gives a more accurate description of how much data the network can handle

### Sharing bandwidth
* We want to approximate the optimal point, that is the point that uses 100% bandwidth efficency and 100% fairness (that is, 100% of the bandwidth is split evenly among all the users using it)
* In practice it is hard to achieve it as a user doesnt know accurately with how many other users it's sharing the network
* TCP: increases as things go well and decreases when a a bad signal is received
* Increase/decrease approaches:
  * Additive: It's linear, increases by +k and decrease by -k
  * Multiplicative: It's geometric, increases by * k and decreases by * 1/k
  * Combination of both: (cartesian product of of additive and multiplicative)
  * Only additive or only multiplicative will not converge to the optimal solution
  * Additive increase with Multiplicative decreases (AIMD) does converge to optimum

### TCP implmentation of congestion control
* Sender needs to know how much the network can handle.
* TCP implements congestion window. Congestion window is not the window size field of the TCP segment header. Congestion window regards the network.
* Congestion window is tracked on the sender. It specifies how many segments can be transmitted.
* TCP will use the minimum of min(congestion window, window size)
* TCP will not start with additive inc multuplicative dec but with exponential (doubles):
![404]({{ site.url }}/images/slowstart.PNG)
* Despite being exponential, the name "slow" start comes from comparing it to the previous algorithm that started the congestion window value = flow control window (window size). Slow start therefore starts with the smallest value as opposed to the maximum.ssssssssssssssssssssssss
* The exponential increase needs to stop before congesting the network:
  * Threshold congestion window size is reached
    * Then swith to increaseing by constant value (additive increase)
    * Threshold value is arbitrary and differs between TCP versions
  * Missing acks indicate a data loss and hence congestion
    * Behaviour depends between TCP versions. TCP Tahoe (first TCP version) would first drop to 1 and set the congestion window to half the previous one and from there switch to additive increase.

![404]({{ site.url }}/images/tcptaho.PNG)

![404]({{ site.url }}/images/reno.PNG)
* Reno moves directly to the half threshold of the congestion window and continues with additive

![404]({{ site.url }}/images/tcpv.PNG)

* Most TCP protocols rely on implicit congestion feedback based on how the network behaves (easier to implement)

## TCP connection release/termination
### Asymmetric disconnect
* Just one guy does it without having to agree on it

### Symmetric disconnect (used by TCP)
* Both parties agree on it
* Two armies problem

![404]({{ site.url }}/images/fin.PNG)

* If you dont get response to the FIN you make (or to the ack if you are the receiver), you make an asymmetric disconnect after some time

## Aplication Layer
### DNS
Domain Name System, an application that enables most of the other applications.
When you want to visit a website, you enter a human-readable name in your browser. However, routing replies on  IP addresses. DNS servers enable you to find the IP address that you are looking for.
* The top level domain is the .com, .gov, .edu, etc, it can be generic (as the examples given before) or country: .es, .nl, .jp, etc. Top level domains are controlled by Internet Corporation for Assigned Names and Numbers (ICANN). There are some politics involved. Originally top level domains end with a dot, (as it is a seperator that also indicates the end), but in practice it is skipped.
* Second-level domains can be requested by orgonizations from registrars
* Once you own a second-level domain, you are free to establish any third-level domains you want within your second-level domain.
* Inputting an address on telnet/firefox should directly send you to the location without going via the name server.

### Name servers
* Name servers are dedicated machines that return the IP address of a human readible address.
* Our operative systems keep track of name servers and dynamically selects which one to use. The location of name servers is configured via DHCP (your internet service provider will hand it to you)
* A custom name server (instead of using the one via DHCP) is called "local name server" (but its not necessarily "local" as you can use a public one like google's dns). The local name server probably doesnt have all the information that you need. The server will contact other servers:
  * **root server**: It has information about all the top level domains
  *  **2nd level domain server**: i.e. a server that knows all the 3rd level domains within ".es"
  *  **3rd level domain server**: same but within a 3rd level domain.
* The local name server might have already cashed the 2nd level domain server.
* The host (i.e. the person that wants to resolve a dns query to visit a website) runs a recursive query, that is, it will first ask the root, then 2nd then 3rd level domain server until obtaining the desired result (and will not just return a partial result), which is sent to the application.
* The name servers between themselves run iterative queries, these guys send the partial results they get (and call it a day) so that the host can move onto asking the subsequent name servers.
* Name servers reply with domain resource records. It may contain:
  * IPv4 address
  * IPv6 address
  * Accepts email yes/no
  * Name server for this domain

## Email
* You can send and receive email on your own domain and give out addresses to your friends
* Or you can use an email service provided by an organization
* An email message contains an envelope, a header and a body
  * Envelope: Fromn: email@address.com, To: email@address.com and Encryption:type
  * Header: From: Name, To: Name, Subject: The subject
  * Body: Hi,...,kind regards, Sergio.
* Email uses multiple protocols
  * Users use POP3 or IMAP (Internet Message Access Protocol) to interact with their mailbox.
    * IMAP sends commands to mail server to manipulate mailboxes
      * LOGIN (into server)
      * FETCH (fetch messages from a folder)
      * CREATE/DELETE (a folder)
      * EXPUNGE (Remove messages marked for deletion)
        * POP 3 would delete all the messages from the server automatically as they are being fetched into a client. However since most people use multiple devices it is better to keep the messages in the server. That's why IMAP replaced POP3. Expunge will delete messages only after loging again. 
  * To send messages users use SMTP (Simple Mail transfer protocol) + Extensions (e.g. AUTH)
  * If people want to send more than just text messages additional headers are introduced via Multipurpose Internet Mail Extensions (MIME)  which contain the content-type such as Text (text/plain, text/html), Images (image/jpeg, image/gif), Video (video/mp4, video/mpeg) or multipart (a combination, for attachment).
    * When MIME was introduced, servers were not expecting non-ASCII data.
    * Binary data would be encoded to make it look like ASCII, then the receiver would have to do the decoding. Base 64 is used.

![404]({{ site.url }}/images/base64table.png)

* Sometimes you have to padd the data of the last 6-bit group. For 2 paddings you append an '=' sign.

### Instant messaging vs email
* Some messaging services use same concept as email (e.g Jabber/XMPP)
  * Choose or set up a server
  * Messages can be sent between parties using different servers
* More commonly, servers are controlled by one party (e.g. WhatsApp, Signal)
  * Often server pusshes messages to receiver rather than letting the reciver be the one that pulls them (eg email).

## World Wide Web
* Webpage: one document on the web
* Website: set of webpages, usually linked under one main domain
* HTTP: Hypertext Transfer Protocol (for fetching and posting data)
* HTML: Hypertext Markup Language (for displaying content on the web browser)
* Web uses Universal Resource Locators (URLs) as an alternative to protocol:IP:port/path

### HTTP requests
* GET: retrieve content, consists of header and body
* HEAD: like get but without body (used for develop, to see whether response exsits, redirects, etc.)
* POST: create new resource, might just add to resource (e.g. comment)
* PUT: put resource, replace current resource
* PATCH: modify existing resource
* DELETE: delete a resource

* HTTP runs on top of TCP
  * TCP uses a 3 way handshake to setup a connection
  * HTTP keeps the current TCP connection alive for requests of the same website (same domain and server)
  * Multiple parallel requests are possible with pipelining (HTTP 1.1)
    * disadvatnage: server has to send responses in the same order it received the requests (bad for performance and abused for attacks)
  * Multiplexing in HTTP2: Give each request a number andmatch based on the number

### HTTP response codes
Responses are grouped in five classes:
1. Informational responses (100–199)
2. Successful responses (200–299)
3. Redirects (300–399)
4. Client errors (400–499)
5. Server errors (500–599)

### MIME types in the Web
* Browser uses MIME type to decide what to do with data
* text/html is parsed
* Other data s passed to a plug-in or another app

